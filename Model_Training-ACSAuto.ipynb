{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from skimage.io import imshow\n",
    "from skimage.transform import resize\n",
    "# from skimage.morphology import label\n",
    "# from skimage.feature import structure_tensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem:\n",
    "# Robustness of the model and transferability, because of different acquisition and muscles and setting on the ultrasound devices\n",
    "# Test if area estimation makes sense when measured if completely automated \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Test whether GPU is present and recognized\n",
    "\n",
    "physical_devices = tf.test.gpu_device_name()\n",
    "print(\"Num GPUs Available: \", len(physical_devices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution block\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size), \\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Create u-net model\n",
    "def get_unet(input_img, n_filters = 64, dropout = 0.1, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    \n",
    "    # Contracting Path\n",
    "    # c is output tensor of conv layers\n",
    "    # p ist output tensor of max pool layers\n",
    "    # u is output tensor of up-sampling (transposed) layers\n",
    "    # Batchnorm standardizes/normalizes the output of each layer where applied in order to avoid huge weights using \n",
    "    # z-scores \n",
    "    \n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Compute Intersection over union (IoU), a measure of labelling accuracy\n",
    "# NOTE: This is sometimes also called Jaccard score\n",
    "def IoU(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
    "    iou = (intersection + smooth) / ( union + smooth)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use only when training new models and not enough data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-714b24907c2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# Choose image & mask that should be augmented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mchosen_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mimage_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"apo_image_csa_RF/insert_images/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mchosen_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mmask_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"apo_masks_csa_RF/insert_masks/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mchosen_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Creating image augmentation function\n",
    "gen = ImageDataGenerator(rotation_range=10, \n",
    "                        width_shift_range=0.1, \n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=0.1,\n",
    "                        horizontal_flip=True)\n",
    "\n",
    "ids = os.listdir(\"apo_image_csa_RF/insert_images\")\n",
    "seed = 1\n",
    "batch_size = 1\n",
    "num_aug_images = 9 # Number of images added from augmented dataset. \n",
    "\n",
    "\n",
    "for i in range(int(len(ids))):\n",
    "    \n",
    "    # Choose image & mask that should be augmented \n",
    "    chosen_image = ids[i] \n",
    "    image_path = \"apo_image_csa_RF/insert_images/\" + chosen_image \n",
    "    mask_path = \"apo_masks_csa_RF/insert_masks/\" + chosen_image\n",
    "    image = np.expand_dims(plt.imread(image_path),0) # Read and expand image dimensions\n",
    "    mask = np.expand_dims(np.expand_dims(plt.imread(mask_path),0),-1)\n",
    "\n",
    "    # Augment images and save to folder \n",
    "    aug_image = gen.flow(image, batch_size=batch_size, seed=seed, save_to_dir=\"apo_image_csa_RF/insert_images\", save_prefix=\"rf\"+str(i), save_format=\"tif\")\n",
    "    aug_mask = gen.flow(mask, batch_size=batch_size, seed=seed, save_to_dir=\"apo_masks_csa_RF/insert_masks\", save_prefix=\"rf\"+str(i), save_format=\"tif\")\n",
    "    \n",
    "    # Add images to folder\n",
    "    for i in range(num_aug_images + 1):\n",
    "        next(aug_image)[0].astype(np.uint8)\n",
    "        next(aug_mask)[0].astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APONEUROSIS TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set image scaling parameters, determine no. of images for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images will be re-scaled\n",
    "im_width = 512\n",
    "im_height = 512\n",
    "border = 5\n",
    "\n",
    "# list of all images in the path\n",
    "#ids = next(os.walk(\"apo_images\"))[2] \n",
    "ids = os.listdir(\"apo_image_csa_RF\")\n",
    "print(\"Total no. of aponeurosis images = \", len(ids))\n",
    "X = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n",
    "y = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images and corresponding labels (masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm is used to display the progress bar\n",
    "for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):\n",
    "    # Load images\n",
    "    img = load_img(\"apo_image_csa_RF/\"+id_, color_mode='grayscale')\n",
    "    x_img = img_to_array(img)\n",
    "    x_img = resize(x_img, (512, 512, 1), mode = 'constant', preserve_range = True)\n",
    "    # Load masks\n",
    "    mask = img_to_array(load_img(\"apo_masks_csa_RF/\"+id_, color_mode='grayscale'))\n",
    "    mask = resize(mask, (512, 512, 1), mode = 'constant', preserve_range = True)\n",
    "    # Normalise and store images\n",
    "    X[n] = x_img/255.0\n",
    "    y[n] = mask/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up aponeurosis training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1) # i.e. 90% training / 10% test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a random image along with the mask (not necessary, just for checking)\n",
    "ix = random.randint(0, len(X_train))\n",
    "has_mask = y_train[ix].max() > 0 # Check whether there's at least 1 aponeurosis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 12))\n",
    "ax1.imshow(X_train[ix, ..., 0], cmap = 'gray', interpolation = 'bilinear')\n",
    "if has_mask: # if at least 1 aponeurosis is present\n",
    "    #draw the aponeuroses on the original image\n",
    "    #ax1.contour(y_train[ix].squeeze(), colors = 'k', linewidths = 0, levels = [0.5])\n",
    "    ax1.set_title('Original image')\n",
    "    ax1.grid(False)\n",
    "    ax2.imshow(y_train[ix].squeeze(), cmap = 'gray', interpolation = 'bilinear')\n",
    "    ax2.set_title('Mask only')\n",
    "    ax2.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the aponeurosis model\n",
    "input_img = Input((im_height, im_width, 1), name='img')\n",
    "model_apo = get_unet(input_img, n_filters=64, dropout=0.25, batchnorm=True)\n",
    "model_apo.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\", IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a summary of the model structure\n",
    "model_apo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some training parameters\n",
    "# Saves the model, lowers learning rate if val los plateaus and performs early stopping. \n",
    "callbacks = [\n",
    "    EarlyStopping(patience=8, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('model-acsa.h5', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "    CSVLogger('acsa_weights.csv', separator=',', append=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the aponeurosis model (keep batch size small!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_apo.fit(X_train, y_train, batch_size=1, epochs=20, callbacks=callbacks, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the results of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables stored in results.history: val_loss, val_acc, val_IoU, loss, acc, IoU, lr\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 8))\n",
    "ax[0].plot(results.history[\"loss\"], label=\"Training loss\")\n",
    "ax[0].plot(results.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax[0].set_title('Learning curve')\n",
    "ax[0].plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"log_loss\")\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(results.history[\"val_IoU\"], label=\"Training IoU\")\n",
    "ax[1].plot(results.history[\"IoU\"], label=\"Validation IoU\")\n",
    "ax[1].set_title(\"IoU curve\")\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"IoU score\")\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.history # Show the loss values (these are saved to a .csv file using 'CSVLogger' callback defined above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training and validations sets\n",
    "preds_train = model_apo.predict(X_train, verbose=1)\n",
    "preds_val = model_apo.predict(X_valid, verbose=1)\n",
    " \n",
    "# Threshold predictions (only keep predictions with a minimum level of confidence)\n",
    "# Value between 0 and 1 for each pixel. 0.5 as threshold to decide wheter to classify pixel as 0 or 1 (1=apo)\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
    "    if ix is None:\n",
    "        ix = random.randint(0, len(X))\n",
    "\n",
    "    has_mask = y[ix].max() > 0\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
    "    ax[0].imshow(X[ix, ..., 0], cmap='Greys_r')\n",
    "    #if has_mask:\n",
    "    #    ax[0].contour(y[ix].squeeze(), colors='w', levels=[0.5])\n",
    "    ax[0].set_title('US-image')\n",
    "    ax[0].grid(False)\n",
    "\n",
    "    ax[1].imshow(y[ix].squeeze(), cmap='Greys_r')\n",
    "    ax[1].set_title('Aponeurosis')\n",
    "    ax[1].grid(False)\n",
    "\n",
    "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1, cmap=\"Greys_r\")\n",
    "    #if has_mask:\n",
    "    #    ax[2].contour(y[ix].squeeze(), colors='w', levels=[0.5])\n",
    "    ax[2].set_title('Apo-Predicted')\n",
    "    ax[2].grid(False)\n",
    "    \n",
    "    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=0.5, cmap=\"Greys_r\")\n",
    "    #if has_mask:\n",
    "    #    ax[3].contour(y[ix].squeeze(), colors='w', levels=[0.5])\n",
    "    ax[3].set_title('Apo-Picture binary')\n",
    "    ax[3].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if training data looks all right\n",
    "plot_sample(X_train, y_train, preds_train, preds_train_t, ix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if valid data looks all right\n",
    "plot_sample(X_valid, y_valid, preds_val, preds_val_t, ix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
