{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages (run once upon startup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division \n",
    "import os\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import skeletonize\n",
    "from scipy.signal import resample, savgol_filter, butter, filtfilt\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from cv2 import EVENT_LBUTTONDOWN\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom function definitions (run once upon startup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import image & prepare directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of Files in directory\n",
    "def get_list_of_files(pathname):\n",
    "    return glob.glob(pathname)\n",
    "\n",
    "# Import image and reshape to desired size\n",
    "def import_reshape_image(path_to_image):\n",
    "    \n",
    "    # Define the image to analyse here and load it\n",
    "    image_add = path_to_image\n",
    "\n",
    "    filename = os.path.splitext(os.path.basename(image_add))[0]\n",
    "    # img = load_img(image_add, color_mode='grayscale')\n",
    "    img = cv2.imread(path_to_image, 0)\n",
    "    print(\"Loaded image at \" + path_to_image)\n",
    "    nonflipped_img = img\n",
    "    img_copy = img\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(20,20))\n",
    "    img = clahe.apply(img)\n",
    "    img = img_to_array(img)\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "    img = np.reshape(img,[-1, h, w,1])\n",
    "    img = resize(img, (1, 256, 256, 1), mode = 'constant', preserve_range = True)\n",
    "    img = img/255.0\n",
    "    img2 = img\n",
    "    return filename, img, img_copy, nonflipped_img, h, w;\n",
    "\n",
    "def get_flip_flags_list(pathname):\n",
    "    flipFlags = []\n",
    "    file = open(pathname, 'r')\n",
    "    for line in file:\n",
    "        for digit in line:\n",
    "            if digit.isdigit():\n",
    "                flipFlags.append(digit)\n",
    "    return flipFlags\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.779856770833334 16.573812362938597 0.11678381 0.064995356 0.556544394772615 0.55654424\n"
     ]
    }
   ],
   "source": [
    "img = load_img(\"C:/Users/Paul/Desktop/img_1.tiff\")\n",
    "img1 = load_img(\"C:/Users/Paul/Desktop/img_2.tiff\")\n",
    "img_n1 =(img_to_array(img) / 255.0)\n",
    "img_n2 =(img_to_array(img1) / 255.0)\n",
    "\n",
    "m1 = np.mean(img)\n",
    "m2 = np.mean(img1)\n",
    "mn1 = np.mean(img_n1)\n",
    "mn2 = np.mean(img_n2)\n",
    "\n",
    "div1 = m2 / m1\n",
    "div2 = mn2 / mn1\n",
    "\n",
    "print(m1, m2, mn1, mn2, div1, div2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect mouse clicks for the purpose of image calibration\n",
    "def mclick(event, x, y, flags, param):\n",
    "    \n",
    "    global mlocs \n",
    "    # if the left mouse button was clicked, record the (x, y) coordinates\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        mlocs.append(y)\n",
    "\n",
    "def calibrate_distance_manually(nonflipped_img, spacing, depth):\n",
    "    # Calibrate the analysis by clicking on 2 points in the image, followed by the 'q' key. These two points should be 1cm apart\n",
    "    # Alternatively, change the spacing setting below\n",
    "    # NOTE: Here we assume that the points are spaced apart in the y/vertical direction of the image\n",
    "    img2 = np.uint8(nonflipped_img)\n",
    "\n",
    "    # display the image and wait for a keypress\n",
    "    cv2.imshow(\"image\", img2)\n",
    "    cv2.setMouseCallback(\"image\", mclick)\n",
    "    key = cv2.waitKey(0)\n",
    " \n",
    "    # if the 'q' key is pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    calib_dist = np.abs(mlocs[0] - mlocs[1])\n",
    "    scalingline_length = depth * calib_dist\n",
    "    print(str(spacing) + ' mm corresponds to ' + str(calib_dist) + ' pixels')\n",
    "    return scalingline_length\n",
    "\n",
    "# Function to calibrate US images with intermittend scaling bars \n",
    "def calibrate_distance_static(nonflipped_img, spacing, depth): \n",
    "    #calibrate analysis according to scale at the right border of the image\n",
    "    img2 = np.uint8(nonflipped_img)\n",
    "    imgscale = img2[70:,1100:1115]#cut out the rightmost part of the picture (the depth scale) by pixels\n",
    "\n",
    "    #search for rows with white pixels, calculate median of distance (index difference) between those rows\n",
    "    calib_dist = np.median(np.diff(np.argwhere(imgscale.sum(axis=1)>200),axis=0))\n",
    "    scalingline_length = depth * calib_dist\n",
    "    print(str(spacing) + ' mm corresponds to ' + str(calib_dist) + ' pixels')\n",
    "    return scalingline_length\n",
    "\n",
    "## Optional, just for plotting \n",
    "def plot_image(image):\n",
    "    img = image\n",
    "    fig, (ax1)= plt.subplots(1, 1, figsize = (15, 15))\n",
    "    ax1.imshow(img, cmap = \"gray\")\n",
    "    ax1.grid(False)\n",
    "    plt.savefig(\"Ridge_test_1.tif\")\n",
    "    \n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    #channel_count = img.shape[2]\n",
    "    match_mask_color = 255\n",
    "    cv2.fillPoly(mask, vertices, match_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_the_lines(img, lines):\n",
    "    img = np.copy(img)\n",
    "    blank_image = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8) # Creating empty image to draw lines on \n",
    "\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(blank_image, (x1,y1), (x2,y2), (0, 255, 0), thickness=1)\n",
    "\n",
    "    img = cv2.addWeighted(img, 0.8, blank_image, 1, 0.0) # Overlay image with lines on original images (only needed for plotting)\n",
    "    return img\n",
    "\n",
    "# Function to calibrate US images with scaling line\n",
    "def calibrate_distance_efov(path_to_image):\n",
    "\n",
    "    image = cv2.imread(path_to_image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Transform BGR Image to RGB\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    # Define ROI with scaling lines\n",
    "    region_of_interest_vertices = [ \n",
    "        (150, height),\n",
    "        (150, 80),\n",
    "        (1100, 80),\n",
    "        (1100, height)\n",
    "    ]\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # Transform RGB to greyscale for edge detection\n",
    "    canny_image = cv2.Canny(gray_image, 400, 600) # Edge detecition\n",
    "    cropped_image = region_of_interest(canny_image,\n",
    "                    np.array([region_of_interest_vertices], np.int32),) \n",
    "    \n",
    "    # For RF\n",
    "    if muscle == \"RF\": \n",
    "        lines = cv2.HoughLinesP(cropped_image,\n",
    "                                rho=1,\n",
    "                                theta=np.pi/180,\n",
    "                                threshold=50,\n",
    "                                lines=np.array([]),\n",
    "                                minLineLength=400,\n",
    "                                maxLineGap=1)\n",
    "        print(lines)\n",
    "        image_with_lines = draw_the_lines(image, lines)\n",
    "\n",
    "    # For VL \n",
    "    if muscle == \"VL\": \n",
    "        lines = cv2.HoughLinesP(cropped_image,\n",
    "                                rho=1, # Distance of pixels in accumulator\n",
    "                                theta=np.pi/180, # Angle resolution in accumulator\n",
    "                                threshold=50, # Only only those lines rutrnes that have higher vote value\n",
    "                                lines=np.array([]),\n",
    "                                minLineLength=200,\n",
    "                                maxLineGap=3) # Gap between lines\n",
    "        image_with_lines = draw_the_lines(image, lines)\n",
    "\n",
    "    # Calculate length of the scaling line\n",
    "    scalingline = lines[0][0]\n",
    "    point1 = [scalingline[0], scalingline[1]]\n",
    "    point2 = [scalingline[2], scalingline[3]]\n",
    "    scalingline_length = math.sqrt(((point1[0]-point2[0])**2)\n",
    "                                   +((point1[1]-point2[1])**2))\n",
    "    #plot_image(image_with_lines)\n",
    "    return scalingline_length\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IoU for modelimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Intersection over union (IoU), a measure of labelling accuracy (sometimes also called Jaccard score)\n",
    "def IoU(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
    "    iou = (intersection + smooth) / ( union + smooth)\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_predictions(img, h, w, filename):\n",
    "    # Get NN predictions for the image\n",
    "\n",
    "    apo_threshold = 0.5 # Set threshold with minimal confidence to make binary \n",
    "    pred_apo = model_apo.predict(img)\n",
    "    pred_apo_t = (pred_apo > apo_threshold).astype(np.uint8) # SET APO THRESHOLD -> makes binary, unisned integer between 0 and 255 = np.uint8\n",
    "    \n",
    "    img = resize(img, (1, h, w, 1))\n",
    "    img = np.reshape(img, (h, w))\n",
    "    pred_apo = resize(pred_apo, (1, h, w,1))\n",
    "    pred_apo = np.reshape(pred_apo, (h, w))\n",
    "    pred_apo_t = resize(pred_apo_t, (1, h, w,1))\n",
    "    pred_apo_t = np.reshape(pred_apo_t, (h, w))\n",
    "\n",
    "    # Uncomment these lines if you want to see the initial predictions\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    ax1 = fig.add_subplot(1,2,1) #Fist is n rows in grid, second n columns, third is position\n",
    "    ax1.imshow(img.squeeze(),cmap='gray')\n",
    "    ax1.grid(False)\n",
    "    ax1.set_title('Original image')\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.imshow(pred_apo_t.squeeze(),cmap=\"gray\")\n",
    "    ax2.grid(False)\n",
    "    ax2.set_title('Aponeuroses')\n",
    "    #plt.savefig(\"./analyzed_images\" + filename)\n",
    "    \n",
    "    return pred_apo_t, fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area calculation and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area\n",
    "def calc_area(depth, scalingline_length, img):\n",
    "\n",
    "    pix_per_cm = scalingline_length / depth\n",
    "    pred_muscle_area = cv2.countNonZero(img) / pix_per_cm**2\n",
    "    #print(pred_muscle_area)\n",
    "    return pred_muscle_area\n",
    "    \n",
    "# Save results\n",
    "def compile_save_results(rootpath, imagepath, filename, muscle, area):\n",
    "    \n",
    "    excelpath = rootpath + '/Results.xlsx'\n",
    "    if os.path.exists(excelpath):\n",
    "        with pd.ExcelWriter(excelpath, mode='a') as writer:\n",
    "            data = pd.DataFrame({'Image_ID': filename, 'Muscle': muscle, 'Area_cm²': area}, index = [0])\n",
    "            data.to_excel(writer)\n",
    "    else:\n",
    "        with pd.ExcelWriter(excelpath, mode='w') as writer:\n",
    "            data = pd.DataFrame({'Image_ID': filename, 'Muscle': muscle, 'Area_cm²': area}, index = [0])\n",
    "            data.to_excel(writer)\n",
    "    \n",
    "# Function to calculate for whole batch\n",
    "def calculate_batch_efov(rootpath):\n",
    "    list_of_files = glob.glob(rootpath + '/**/*.tif', recursive=True)\n",
    "    \n",
    "    with PdfPages(rootpath + '/Analyzed_images.pdf') as pdf:  \n",
    "            \n",
    "        for imagepath in list_of_files:\n",
    "\n",
    "            filename, img, img_copy, nonflipped_img, h, w = import_reshape_image(imagepath) \n",
    "            scalingline_length = calibrate_distance_efov(imagepath)\n",
    "                   \n",
    "            img, fig = do_predictions(img, h, w, filename)\n",
    "            area = calc_area(depth, scalingline_length, img)\n",
    "            compile_save_results(rootpath, imagepath, filename, muscle, area)\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "    \n",
    "\n",
    "# Function to calculate for whole batch\n",
    "def calculate_batch(rootpath, flip_file_path):\n",
    "    list_of_files = glob.glob(rootpath + '/**/*.tif', recursive=True)\n",
    "    flip_flags = get_flip_flags_list(flip_file_path)\n",
    "    \n",
    "    with PdfPages(rootpath + '/Analyzed_images.pdf') as pdf:\n",
    "        \n",
    "        if(len(list_of_files) == len(flip_flags)):\n",
    "            \n",
    "            for imagepath in list_of_files:\n",
    "                \n",
    "                flip = flip_flags.pop(0)\n",
    "                filename, img, img_copy, nonflipped_img, h, w = import_reshape_image(imagepath)\n",
    "                \n",
    "                if scaling == \"Static\": \n",
    "                    \n",
    "                    scalingline_length = calibrate_distance_static(nonflipped_img, spacing, depth)\n",
    "                \n",
    "                else: \n",
    "                    \n",
    "                    scalingline_length = calibrate_distance_manually(nonflipped_img, spacing, depth)\n",
    "                                       \n",
    "                img, fig = do_predictions(img, h, w, filename)\n",
    "                area = calc_area(depth, scalingline_length, img)\n",
    "                compile_save_results(rootpath, imagepath, filename, muscle, area)\n",
    "                pdf.savefig(fig)\n",
    "                plt.close(fig)\n",
    "        else:\n",
    "            print(\"Warning: number of flipFlags doesn\\'t match number of images! Calculations aborted.\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_apo = load_model(\"C:/Users/Paul/Desktop/Test_image/model/model.h5\", custom_objects={'IoU': IoU})\n",
    "depth = 6\n",
    "muscle = \"RF\" # VL / GM\n",
    "scaling = \"EFOV\" # Static / Manual\n",
    "spacing = 5 \n",
    "mlocs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scaling == \"EFOV\": \n",
    "    calculate_batch_efov(\"C:/Users/paul/Desktop/Test_image\")\n",
    "else: \n",
    "    calculate_batch(\"C:/Users/paul/Desktop/Test_image\",\n",
    "                        \"C:/Users/paul/Desktop/Test_image/Flip.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
